var documenterSearchIndex = {"docs":
[{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [NODEData]","category":"page"},{"location":"reference/#NODEData.LargeNODEDataloader","page":"Reference","title":"NODEData.LargeNODEDataloader","text":"LargeNODEDataloader(sol, N_batch, N_length, name, base_path=\"\"; dt=nothing, valid_set=nothing)\n\nImpelements an array of NODEDataloader that are too large for the RAM and are thus saved to the hard drive (temporally). They can be loaded by just indexing the \n\n\n\n\n\n","category":"type"},{"location":"reference/#NODEData.NODEDataloader","page":"Reference","title":"NODEData.NODEDataloader","text":"NODEDataloader{T,N} <: AbstractNODEDataloader{T,N}\n\nStruct containing batched data for sequence learning of ODEs. Can be indexed and interated over. Each batch returns a tuple (t, data(t)).\n\nInitialized with\n\nNODEData(sol::SciMLBase.AbstractTimeseriesSolution, N_length::Integer; dt=nothing, valid_set=nothing, GPU=nothing)\n\nsol: DE solution\nN_length: length of each batch\ndt: time increment that sol is interpolated at. If nothing then the sol.t is used as the time steps of the data\nvalid_set if validset âˆˆ [0,1] splits the data into a train and valid set with `validset` of the share of the data belonging to the valid_set.\nGPU if nothing the output is automatically chosen to be on GPU/CPU based on sol, if GPU==true or GPU==false the automatic choice is overwritten\nNODEDataloader(data::AbstractArray{T,N}, t::AbstractArray{T,1}, N_length::Integer)\ndata:: Data that is already in Ndim1 x ... x N_t format\nt: time axis\nN_length: length of each batch\n\n\n\n\n\n","category":"type"},{"location":"reference/#NODEData.SingleTrajectoryBatchedOSADataloader-Union{Tuple{N}, Tuple{U}, Tuple{T}, Tuple{AbstractArray{T, N}, AbstractVector{U}}, Tuple{AbstractArray{T, N}, AbstractVector{U}, Int64}} where {T, U, N}","page":"Reference","title":"NODEData.SingleTrajectoryBatchedOSADataloader","text":"SingleTrajectoryBatchedOSADataloader(data::AbstractArray{T,N}, t::AbstractArray{U,1}, N_batch::Int=1; valid_set=nothing, GPU::Union{Bool, Nothing}=nothing) where {T,U,N}\n\nPrepares a single trajectory batches one-step-ahead dataloader. When indexed it returns tuples (t, x) which are batches of 2-element trajectories, so that they contain the initial condition and one step ahead of the dynamical system. The batches are in format (Ndims ... x Nbatch x N_t). t contains the time information of each of these trajectory snippets. \n\nInputs\n\ndata: Trajectory (Ndims .... x Nt)\nt: time steps of the trajectory \n\n\n\n\n\n","category":"method"},{"location":"reference/#NODEData.MultiTrajectoryBatchedNODEDataloader-Tuple{AbstractVector, Integer}","page":"Reference","title":"NODEData.MultiTrajectoryBatchedNODEDataloader","text":"MultiTrajectoryBatchedNODEDataloader(trajectories::AbstractVector, N_length::Integer; valid_set=nothing, GPU::Union{Bool, Nothing}=nothing) where {T,U,N}\n\ntrajectories is a Vector of trajectories/tuples (t, x(t)), for the batched NODEDataloader it is assumed that all t are equal, and only the first one is used. The constructor enforces the equal length, but only warns about non-equal elements\n\nActually the routine just wraps around NODEDataloader but concatanates the trajectories in such a way that it works with it. \n\n\n\n\n\n","category":"method"},{"location":"reference/#NODEData.detect_sol_array_type-Tuple{RecursiveArrayTools.AbstractDiffEqArray}","page":"Reference","title":"NODEData.detect_sol_array_type","text":"detect_sol_array_type(sol::Union{SciMLBase.AbstractTimeseriesSolution, SciMLBase.AbstractDiffEqArray})\n\nReturns true if the solution is on a GPU, false if it is not CPU. \n\n\n\n\n\n","category":"method"},{"location":"reference/#NODEData.get_trajectory-Tuple{NODEData.SingleTrajectoryBatchedOSADataloader, Any}","page":"Reference","title":"NODEData.get_trajectory","text":"get_trajectory(data::SingleTrajectoryBatchedOSADataloader{T,U,N}, N)\n\nReturns a (t, x(t)) tuple of length N.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NODEData.get_trajectory-Tuple{NODEDataloader, Any}","page":"Reference","title":"NODEData.get_trajectory","text":"get_trajectory(data::NODEDataloader, N)\n\nReturns a (t, x(t)) tuple of length N.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NODEData.gpuoff-Tuple{}","page":"Reference","title":"NODEData.gpuoff","text":"gpuoff()\n\nManually toggle GPU use off\n\n\n\n\n\n","category":"method"},{"location":"reference/#NODEData.gpuon-Tuple{}","page":"Reference","title":"NODEData.gpuon","text":"gpuon()\n\nManually toggle GPU use on (if available)\n\n\n\n\n\n","category":"method"},{"location":"reference/#NODEData.single_trajectory_from_batched-Tuple{NODEDataloader, Int64}","page":"Reference","title":"NODEData.single_trajectory_from_batched","text":"single_trajectory_from_batched(data::NODEDataloader, N::Int)\n\nReturns a single trajectory (t,x(t)) fomr the dataloader but repeats it along the N_batch dimension. Useful for testing the performance of methods that can't change the batch size dynamically. \n\n\n\n\n\n","category":"method"},{"location":"#NODEData","page":"Home","title":"NODEData","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Small helper package that provides a struct for sequence learning with Neural ODEs. It behaves roughly similar to Flux' Dataloader but the individual samples overlap, so that it is suitable for learning sequences.","category":"page"},{"location":"#Usage","page":"Home","title":"Usage","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Prepare a DE solution","category":"page"},{"location":"","page":"Home","title":"Home","text":"f(u,p,t) = 1.01*u\nu0 = 1/2\ntspan = (0.0,10.0)\nprob = ODEProblem(f,u0,tspan)\nsol = solve(prob, Tsit5(), reltol=1e-8, abstol=1e-8)","category":"page"},{"location":"","page":"Home","title":"Home","text":"and either interpolate the result","category":"page"},{"location":"","page":"Home","title":"Home","text":"data = NODEDataloader(sol, 20, dt=0.2)","category":"page"},{"location":"","page":"Home","title":"Home","text":"or use their original timesteps","category":"page"},{"location":"","page":"Home","title":"Home","text":"data = NODEDataloader(sol, 20)","category":"page"},{"location":"","page":"Home","title":"Home","text":"In these examples each batch is N_length=20 elements long, i.e data[i], is a tuple with (t, data(t)) each with 20 elements. data[1] are the first N_length elements, data[2] are the 2:N_length+1 elements and so on.","category":"page"},{"location":"#Larger-than-RAM-data","page":"Home","title":"Larger than RAM data","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The pacakge also provides a wrapper around NODEDataloader for larger than RAM datasets. The data is split into temporary files on the harddrive and can be easiliy loaded. See LargeNODEDataloader","category":"page"}]
}
