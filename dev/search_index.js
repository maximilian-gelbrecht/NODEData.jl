var documenterSearchIndex = {"docs":
[{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [NODEData]","category":"page"},{"location":"reference/#NODEData.LargeNODEDataloader","page":"Reference","title":"NODEData.LargeNODEDataloader","text":"LargeNODEDataloader(sol, N_batch, N_length, name, base_path=\"\"; dt=nothing, valid_set=nothing)\n\nImpelements an array of NODEDataloader that are too large for the RAM and are thus saved to the hard drive (temporally). They can be loaded by just indexing the \n\n\n\n\n\n","category":"type"},{"location":"reference/#NODEData.NODEDataloader","page":"Reference","title":"NODEData.NODEDataloader","text":"NODEDataloader{T,N} <: AbstractNODEDataloader{T,N}\n\nStruct containing batched data for sequence learning of ODEs. Can be indexed and interated over. Each batch returns a tuple (t, data(t)).\n\nInitialized with\n\nNODEData(sol::SciMLBase.AbstractTimeseriesSolution, N_length::Integer; dt=nothing, valid_set=nothing)\n\nsol: DE solution\nN_length: length of each batch\ndt: time increment that sol is interpolated at. If nothing then the sol.t is used as the time steps of the data\nvalid_set if validset âˆˆ [0,1] splits the data into a train and valid set with `validset` of the share of the data belonging to the valid_set.\nNODEDataloader(data::AbstractArray{T,N}, t::AbstractArray{T,1}, N_length::Integer)\ndata:: Data that is already in Ndim1 x ... x N_t format\nt: time axis\nN_length: length of each batch\n\n\n\n\n\n","category":"type"},{"location":"reference/#NODEData.get_trajectory-Tuple{NODEDataloader, Any}","page":"Reference","title":"NODEData.get_trajectory","text":"get_trajectory(data::NODEDataloader, N)\n\nReturns a (t, x(t)) tuple of length N.\n\n\n\n\n\n","category":"method"},{"location":"reference/#NODEData.gpuoff-Tuple{}","page":"Reference","title":"NODEData.gpuoff","text":"gpuoff()\n\nManually toggle GPU use off\n\n\n\n\n\n","category":"method"},{"location":"reference/#NODEData.gpuon-Tuple{}","page":"Reference","title":"NODEData.gpuon","text":"gpuon()\n\nManually toggle GPU use on (if available)\n\n\n\n\n\n","category":"method"},{"location":"#NODEData","page":"Home","title":"NODEData","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Small helper package that provides a struct for sequence learning with Neural ODEs. It behaves roughly similar to Flux' Dataloader but the individual samples overlap, so that it is suitable for learning sequences.","category":"page"},{"location":"#Usage","page":"Home","title":"Usage","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Prepare a DE solution","category":"page"},{"location":"","page":"Home","title":"Home","text":"f(u,p,t) = 1.01*u\nu0 = 1/2\ntspan = (0.0,10.0)\nprob = ODEProblem(f,u0,tspan)\nsol = solve(prob, Tsit5(), reltol=1e-8, abstol=1e-8)","category":"page"},{"location":"","page":"Home","title":"Home","text":"and either interpolate the result","category":"page"},{"location":"","page":"Home","title":"Home","text":"data = NODEDataloader(sol, 20, dt=0.2)","category":"page"},{"location":"","page":"Home","title":"Home","text":"or use their original timesteps","category":"page"},{"location":"","page":"Home","title":"Home","text":"data = NODEDataloader(sol, 20)","category":"page"},{"location":"","page":"Home","title":"Home","text":"In these examples each batch is N_length=20 elements long, i.e data[i], is a tuple with (t, data(t)) each with 20 elements. data[1] are the first N_length elements, data[2] are the 2:N_length+1 elements and so on.","category":"page"},{"location":"#Larger-than-RAM-data","page":"Home","title":"Larger than RAM data","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The pacakge also provides a wrapper around NODEDataloader for larger than RAM datasets. The data is split into temporary files on the harddrive and can be easiliy loaded. See LargeNODEDataloader","category":"page"}]
}
